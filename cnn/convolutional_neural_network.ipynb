{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "ofMHg2o5DyN8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wDa5uySRECB3",
        "outputId": "d612cffd-e547-4108-e072-c08751fa167c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will do apply image transformation on image training dataset that will help in handling overfitting\n",
        "# these transformation are:-\n",
        "# 1)geometrical transformation to shift some of the pixels\n",
        "# 2)horizontal flips\n",
        "# 3)zoom in and zoom out\n",
        "# all these transformation are called image augmentation\n"
      ],
      "metadata": {
        "id": "scDAftciETLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2\n",
        ")\n",
        "train_set = keras.utils.image_dataset_from_directory(\n",
        "    directory='F:\\manage\\imp folder\\deep learning\\cnn\\Section+40+-+Convolutional+Neural+Networks+(CNN)\\Section 40 - Convolutional Neural Networks (CNN)\\dataset\\training_set',\n",
        "\n",
        "    batch_size=32,\n",
        "    image_size=(64, 64)\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "3n48yWqHHPl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./25)\n",
        "train_set = keras.utils.image_dataset_from_directory(\n",
        "    directory='F:\\manage\\imp folder\\deep learning\\cnn\\Section+40+-+Convolutional+Neural+Networks+(CNN)\\Section 40 - Convolutional Neural Networks (CNN)\\dataset\\test_set',\n",
        "    batch_size=32,\n",
        "    image_size=(64, 64)\n",
        "    )"
      ],
      "metadata": {
        "id": "pAQVyHJVJIw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn=tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "_VFkkYmNLgcw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=35,kernel_size=3,activation='relu',input_shape=[64,64,3]))\n",
        "# filters will tell how many filter we want to apply\n",
        "# kernel _size will specify the size of the filter ex:-3*3,2*2 etc.\n",
        "# input_shape will tell the size of our image\n",
        "# we have to choose activation function as well"
      ],
      "metadata": {
        "id": "2Op0lw_SLT4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to apply max pooling\n",
        "# now we are adding pool layer to our nueral network\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
        "# strides is that how many pixels you want to shift for taking each square \n",
        "# "
      ],
      "metadata": {
        "id": "yVXFf5jsNMki"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now since the input shape parameter has changed so we have to change that accordingly\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n"
      ],
      "metadata": {
        "id": "F_bSiCCCOO2h"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "l8p1xWNKPkU6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this time we will take dense class since it is a hidden layer\n",
        "# units =no of nuerons in that layer\n",
        "# activation=rectifier activation function\n",
        "cnn.add(tf.keras.layers.Dense(units=136,activation='relu'))"
      ],
      "metadata": {
        "id": "ErMjcYEfPs4F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since it also an hidden layers hence we need to call the dense class again\n",
        "# we need only one neuron since we are doing binary classification\n",
        "# thats why also we have to  use sigmoid function but in case of multilayer output we have to use softmax function\n",
        "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "x9a6p1yvQpwz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we are making the brain of cnn smarter\n"
      ],
      "metadata": {
        "id": "qnGuWjWaRTQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to choose an optimizer ,a loss function and metrics that will tell how good our prediction are\n",
        "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "dnzPKiiWRil0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x=train_set,validation_data=test_set,epochs=20)"
      ],
      "metadata": {
        "id": "TFXsns3kTNYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "# we need to import image module\n",
        "from keras.preprocessing import image\n",
        "# loading that single image\n",
        "# we need to add path\n",
        "# we need to make the size same as the training image size-target_size\n",
        "# predict method expect the image as array\n",
        "# we have to convert pil method of image to array-img_to_array-\n",
        "my_test_image=image.load_img(path='F:\\manage\\imp folder\\deep learning\\cnn\\Section+40+-+Convolutional+Neural+Networks+(CNN)\\Section 40 - Convolutional Neural Networks (CNN)\\dataset\\single_prediction/dog.jpg',target_size=(64,64))\n",
        "my_test_image=image.img_to_array()\n",
        "# when we trained our cnn models we trained it by sending batches of images so\n",
        "# now we have to specify it that we want to send only a single image\n",
        "# we will use numpy to convert \n",
        "# also we have to add this extra dimension and where we need to add this dimension\n",
        "test_image=np.expand_dims(my_test_image,axis=0)\n",
        "# lets get our output now\n",
        "result=cnn.predict(test_image)\n",
        "# how to figure 0/1 which is dog or which is cat\n",
        "# we have to cal class_indices \n",
        "train_set.class_indices\n",
        "if(result[0][0]==0):\n",
        "  print(\"we got a cat\")\n",
        "else:\n",
        "  print(\" we got a dog\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "iSyU0-H9TrPo",
        "outputId": "73f3516e-2efb-42ac-dd6f-c9711423b791"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7c3ff5a48dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# predict method expect the image as array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# we have to convert pil method of image to array-img_to_array-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmy_test_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F:\\manage\\imp folder\\deep learning\\cnn\\Section+40+-+Convolutional+Neural+Networks+(CNN)\\Section 40 - Convolutional Neural Networks (CNN)\\dataset\\single_prediction/dog.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmy_test_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# when we trained our cnn models we trained it by sending batches of images so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m    313\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 314\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:\\\\manage\\\\imp folder\\\\deep learning\\\\cnn\\\\Section+40+-+Convolutional+Neural+Networks+(CNN)\\\\Section 40 - Convolutional Neural Networks (CNN)\\\\dataset\\\\single_prediction/dog.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JTus94BLfo-B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}